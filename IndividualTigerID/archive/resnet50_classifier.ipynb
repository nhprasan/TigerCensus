{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/u3/prasan/.local/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/u3/prasan/.local/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in /home/u3/prasan/.local/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: pytorch-lightning in /home/u3/prasan/.local/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: networkx in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: filelock in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/u3/prasan/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/u3/prasan/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\n",
      "Requirement already satisfied: numpy in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from torchvision) (1.22.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from pytorch-lightning) (0.11.7)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.4.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/u3/prasan/.local/lib/python3.8/site-packages (from fsspec->torch) (3.10.7)\n",
      "Requirement already satisfied: setuptools in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (60.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from packaging>=20.0->pytorch-lightning) (3.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (2.4.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/u3/prasan/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch) (3.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/opt/ohpc/pub/apps/python/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install libraries \n",
    "!pip install lightning torch==1.10.1 torchaudio==0.10.1 torchvision==0.11.2 pytorch-lightning==1.9.0 lightning-utilities==0.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of the Classifier\n",
    "\n",
    "as defined by our Capstone project primary paper \"PyTorch-Wildlife\" GitHub repository.\n",
    "\n",
    "References:\n",
    "- https://github.com/microsoft/CameraTraps/blob/main/PW_FT_classification/src/models/plain_resnet.py\n",
    "- https://github.com/microsoft/CameraTraps/blob/main/PW_FT_classification/src/algorithms/plain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision.models.resnet import Bottleneck, ResNet\n",
    "from torchvision.models.resnet import *\n",
    "\n",
    "# Try importing a function to load pre-trained weights; if not available, use an alternative.\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_state_dict_from_url\n",
    "\n",
    "# Exportable class names for external use\n",
    "__all__ = [\n",
    "    'PlainResNetClassifier',  # Custom ResNet classifier\n",
    "    'Plain'  # PyTorch Lightning model wrapper\n",
    "]\n",
    "\n",
    "# Pre-trained model URL for initializing ResNet-50 with pretrained weights (ImageNet).\n",
    "model_urls = {\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-0676ba61.pth'\n",
    "}\n",
    "\n",
    "class ResNetBackbone(ResNet):\n",
    "    \"\"\"\n",
    "    Custom ResNet backbone class for feature extraction.\n",
    "    Inherits from the original ResNet class to use it as a feature extractor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64,\n",
    "                 replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        \"\"\"\n",
    "        Initialize the ResNet backbone.\n",
    "        Args:\n",
    "            - block: The building block used in ResNet (e.g., Bottleneck).\n",
    "            - layers: Number of layers in each stage.\n",
    "            - zero_init_residual: If True, zero-initialize the residual connection.\n",
    "            - groups, width_per_group: Controls for ResNet's internal structure.\n",
    "            - replace_stride_with_dilation: Dilation to replace strides.\n",
    "            - norm_layer: The normalization layer to use.\n",
    "        \"\"\"\n",
    "        super(ResNetBackbone, self).__init__(\n",
    "            block=block,\n",
    "            layers=layers,\n",
    "            zero_init_residual=zero_init_residual,\n",
    "            groups=groups,\n",
    "            width_per_group=width_per_group,\n",
    "            replace_stride_with_dilation=replace_stride_with_dilation,\n",
    "            norm_layer=norm_layer,\n",
    "        )\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass implementation for the ResNet backbone.\n",
    "        \"\"\"\n",
    "        # Apply initial convolution, batch norm, and max pooling.\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Pass through each ResNet layer sequentially.\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # Apply global average pooling and flatten the tensor.\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "class PlainResNetClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom ResNet classifier class that utilizes the ResNet backbone.\n",
    "    \"\"\"\n",
    "\n",
    "    name = 'PlainResNetClassifier'\n",
    "\n",
    "    def __init__(self, num_cls=2, num_layers=50):\n",
    "        \"\"\"\n",
    "        Initialize the PlainResNetClassifier.\n",
    "        Args:\n",
    "            - num_cls: Number of classes to classify.\n",
    "            - num_layers: Number of layers in the ResNet (e.g., 50 for ResNet-50).\n",
    "        \"\"\"\n",
    "        super(PlainResNetClassifier, self).__init__()\n",
    "        self.num_cls = num_cls\n",
    "        self.num_layers = num_layers\n",
    "        self.feature = None  # Backbone for feature extraction.\n",
    "        self.classifier = None  # Linear layer for classification.\n",
    "        self.criterion_cls = None  # Loss criterion.\n",
    "\n",
    "        # Initialize the network architecture and load pre-trained weights.\n",
    "        self.setup_net()\n",
    "\n",
    "    def setup_net(self):\n",
    "        \"\"\"\n",
    "        Set up the ResNet network and initialize its weights.\n",
    "        \"\"\"\n",
    "        kwargs = {}  # Optional parameters for ResNet configuration.\n",
    "\n",
    "        # Choose architecture based on specified layer count.\n",
    "        if self.num_layers == 50:\n",
    "            block = Bottleneck  # Use Bottleneck block for ResNet-50.\n",
    "            layers = [3, 4, 6, 3]  # Standard layer configuration for ResNet-50.\n",
    "            # Load pre-trained ResNet-50 weights.\n",
    "            self.pretrained_weights = load_state_dict_from_url(\n",
    "                model_urls['resnet50'], progress=True)\n",
    "        else:\n",
    "            raise Exception('ResNet Type not supported.')\n",
    "\n",
    "        # Construct the feature extractor and classifier.\n",
    "        self.feature = ResNetBackbone(block, layers, **kwargs)\n",
    "        self.classifier = nn.Linear(512 * block.expansion, self.num_cls)\n",
    "\n",
    "    def setup_criteria(self):\n",
    "        \"\"\"\n",
    "        Set up the criterion (loss function) for classification.\n",
    "        \"\"\"\n",
    "        self.criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "class Plain(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Defines the architecture for training a model using PyTorch Lightning.\n",
    "    \"\"\"\n",
    "\n",
    "    name = 'Plain'\n",
    "\n",
    "    def __init__(self, conf, train_class_counts, id_to_labels, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the Plain model.\n",
    "        Args:\n",
    "            - conf: Configuration object containing training parameters.\n",
    "            - train_class_counts: List of class counts for training.\n",
    "            - id_to_labels: Dictionary mapping class indices to labels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Store hyperparameters from the configuration object.\n",
    "        self.hparams.update(conf.__dict__)\n",
    "        self.save_hyperparameters(ignore=['conf', 'train_class_counts'])\n",
    "        self.train_class_counts = train_class_counts  # Store class counts.\n",
    "        self.id_to_labels = id_to_labels  # Store class label mappings.\n",
    "        # Initialize the custom ResNet-based classifier.\n",
    "        self.net = PlainResNetClassifier(num_cls=self.hparams.num_classes,\n",
    "                                          num_layers=self.hparams.num_layers)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizers and learning rate schedulers.\n",
    "        \"\"\"\n",
    "        # Define parameters for the optimizer, separating feature and classifier parameters.\n",
    "        net_optim_params_list = [\n",
    "            # Feature extraction parameters.\n",
    "            {'params': self.net.feature.parameters(),\n",
    "             'lr': self.hparams.lr_feature,\n",
    "             'momentum': self.hparams.momentum_feature,\n",
    "             'weight_decay': self.hparams.weight_decay_feature},\n",
    "            # Classifier parameters.\n",
    "            {'params': self.net.classifier.parameters(),\n",
    "             'lr': self.hparams.lr_classifier,\n",
    "             'momentum': self.hparams.momentum_classifier,\n",
    "             'weight_decay': self.hparams.weight_decay_classifier}\n",
    "        ]\n",
    "        # Setup optimizer and learning rate scheduler.\n",
    "        optimizer = torch.optim.SGD(net_optim_params_list)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"\n",
    "        Hook function called at the start of training.\n",
    "        Initializes best accuracy and sets up the loss function.\n",
    "        \"\"\"\n",
    "        self.net.setup_criteria()  # Set up the loss function for classification.\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step for each batch.\n",
    "\n",
    "        Args:\n",
    "            batch: The current batch of data containing inputs and labels.\n",
    "            batch_idx: The index of the current batch.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The loss for the current training step.\n",
    "        \"\"\"\n",
    "        data, label_ids = batch[0], batch[1]  # Unpack batch data into features and labels.\n",
    "\n",
    "        # Forward pass through feature extractor and classifier.\n",
    "        feats = self.net.feature(data)  # Extract features from the input data.\n",
    "        logits = self.net.classifier(feats)  # Classify the extracted features.\n",
    "\n",
    "        # Calculate loss using the criterion (cross-entropy loss between predictions and true labels).\n",
    "        loss = self.net.criterion_cls(logits, label_ids)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        \"\"\"\n",
    "        Hook function called at the start of validation.\n",
    "        Initializes storage for validation outputs.\n",
    "        \"\"\"\n",
    "        self.val_st_outs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step for each batch.\n",
    "\n",
    "        Args:\n",
    "            batch: The current batch of data containing inputs and labels.\n",
    "            batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        data, label_ids = batch[0], batch[1]  # Unpack batch data into features and labels.\n",
    "\n",
    "        # Forward pass through the network for validation.\n",
    "        feats = self.net.feature(data)  # Extract features from the validation data.\n",
    "        logits = self.net.classifier(feats)  # Classify the extracted features.\n",
    "        preds = logits.argmax(dim=1)  # Get the predicted class labels.\n",
    "\n",
    "        # Append predictions and true labels to the validation output list.\n",
    "        self.val_st_outs.append((preds.detach().cpu().numpy(),  # Store predictions.\n",
    "                                 label_ids.detach().cpu().numpy()))  # Store true labels.\n",
    "\n",
    "    def on_test_start(self):\n",
    "        \"\"\"\n",
    "        Hook function called at the start of testing.\n",
    "        Initializes storage for test outputs.\n",
    "        \"\"\"\n",
    "        self.te_st_outs = []\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step for each batch.\n",
    "\n",
    "        Args:\n",
    "            batch: The current batch of data, including metadata.\n",
    "            batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        data, label_ids, labels, file_ids = batch  # Unpack batch data (features, true labels, additional metadata).\n",
    "\n",
    "        # Forward pass through the network for testing.\n",
    "        feats = self.net.feature(data)  # Extract features from the test data.\n",
    "        logits = self.net.classifier(feats)  # Classify the extracted features.\n",
    "        preds = logits.argmax(dim=1)  # Get the predicted class labels.\n",
    "\n",
    "        # Append predictions and relevant data to the test output list.\n",
    "        self.te_st_outs.append((preds.detach().cpu().numpy(),  # Store predictions.\n",
    "                               label_ids.detach().cpu().numpy(),  # Store true labels.\n",
    "                               feats.detach().cpu().numpy(),  # Store features for analysis.\n",
    "                               logits.detach().cpu().numpy(),  # Store raw logits for further inspection.\n",
    "                               labels, file_ids))  # Store additional metadata.\n",
    "\n",
    "    def on_predict_start(self):\n",
    "        \"\"\"\n",
    "        Hook function called at the start of prediction.\n",
    "        Initializes storage for prediction outputs.\n",
    "        \"\"\"\n",
    "        self.pr_st_outs = []\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Prediction step for each batch.\n",
    "\n",
    "        Args:\n",
    "            batch: The current batch of data, including metadata.\n",
    "            batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        data, file_ids = batch  # Unpack batch data into features and metadata.\n",
    "\n",
    "        # Forward pass through the network for predictions.\n",
    "        feats = self.net.feature(data)  # Extract features from the input data.\n",
    "        logits = self.net.classifier(feats)  # Classify the extracted features.\n",
    "        preds = logits.argmax(dim=1)  # Get the predicted class labels.\n",
    "\n",
    "        # Append predictions and relevant data to the prediction output list.\n",
    "        self.pr_st_outs.append((preds.detach().cpu().numpy(),  # Store predictions.\n",
    "                               feats.detach().cpu().numpy(),  # Store extracted features.\n",
    "                               logits.detach().cpu().numpy(),  # Store raw logits for analysis.\n",
    "                               file_ids))  # Store file IDs for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5050/2461769364.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameters:\n",
      "{'conf_id': 'Crop_res50_plain_082723', 'algorithm': 'Plain', 'log_dir': 'Crop', 'num_epochs': 15, 'log_interval': 10, 'parallel': 0, 'dataset_root': './data/imgs', 'dataset_name': 'Custom_Crop', 'annotation_dir': './data/imgs', 'split_path': './data/imgs/tiger_binary.csv', 'test_size': 0.2, 'val_size': 0.2, 'split_data': True, 'split_type': 'random', 'batch_size': 32, 'num_workers': 8, 'num_classes': 2, 'model_name': 'PlainResNetClassifier', 'num_layers': 50, 'weights_init': 'ImageNet', 'lr_feature': 0.01, 'momentum_feature': 0.9, 'weight_decay_feature': 0.0005, 'lr_classifier': 0.01, 'momentum_classifier': 0.9, 'weight_decay_classifier': 0.0005, 'step_size': 10, 'gamma': 0.1, 'evaluate': None, 'val': False, 'predict': False, 'predict_root': '', 'id_to_labels': {0: 'Not Tiger', 1: 'Tiger'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the trained ResNet-50 checkpoint file\n",
    "checkpoint_path = 'weights/Crop/Plain/Crop_res50_plain_082723-0-epoch=14-valid_mac_acc=91.38.ckpt'\n",
    "\n",
    "# Load the checkpoint file\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Accessing the Hyperparameters used for training the classifier\n",
    "hyper_parameters = checkpoint['hyper_parameters']\n",
    "\n",
    "print(\"\\nHyperparameters:\")\n",
    "print(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain(\n",
      "  (net): PlainResNetClassifier(\n",
      "    (feature): ResNetBackbone(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "    (classifier): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Configuration class to specify model parameters.\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Hyperparameters extracted from the Crop_res50_plain_082723-0-epoch=14-valid_mac_acc=91.38.ckpt checkpoint file\n",
    "        self.conf_id = 'Crop_res50_plain_082723'  # Configuration ID\n",
    "        self.algorithm = 'Plain'  # Algorithm name\n",
    "        self.log_dir = 'Crop'  # Directory for logs\n",
    "        self.num_epochs = 15  # Number of epochs\n",
    "        self.log_interval = 10  # Interval for logging\n",
    "        self.parallel = 0  # Parallel processing flag\n",
    "        self.dataset_root = './data/imgs'  # Root directory of the dataset\n",
    "        self.dataset_name = 'Custom_Crop'  # Name of the dataset\n",
    "        self.annotation_dir = './data/imgs'  # Directory for annotations\n",
    "        self.split_path = './data/imgs/tiger_binary.csv'  # Path to split file\n",
    "        self.test_size = 0.2  # Proportion of data to use for testing\n",
    "        self.val_size = 0.2  # Proportion of data to use for validation\n",
    "        self.split_data = True  # Flag indicating whether to split data\n",
    "        self.split_type = 'random'  # Method for splitting the dataset\n",
    "        self.batch_size = 32  # Batch size for training\n",
    "        self.num_workers = 8  # Number of workers for data loading\n",
    "        self.num_classes = 2  # Number of classes in the classification task\n",
    "        self.model_name = 'PlainResNetClassifier'  # Name of the model\n",
    "        self.num_layers = 50  # Number of layers in the ResNet model\n",
    "        self.weights_init = 'ImageNet'  # Weight initialization strategy\n",
    "        self.lr_feature = 0.01  # Learning rate for feature extractor\n",
    "        self.momentum_feature = 0.9  # Momentum for feature extractor optimizer\n",
    "        self.weight_decay_feature = 0.0005  # Weight decay for feature extractor\n",
    "        self.lr_classifier = 0.01  # Learning rate for classifier\n",
    "        self.momentum_classifier = 0.9  # Momentum for classifier optimizer\n",
    "        self.weight_decay_classifier = 0.0005  # Weight decay for classifier\n",
    "        self.step_size = 10  # Step size for learning rate scheduler\n",
    "        self.gamma = 0.1  # Learning rate decay factor\n",
    "        self.evaluate = None  # Evaluation flag\n",
    "        self.val = False  # Validation flag\n",
    "        self.predict = False  # Prediction flag\n",
    "        self.predict_root = ''  # Directory for prediction data\n",
    "        self.id_to_labels = {0: 'Not Tiger', 1: 'Tiger'}  # Mapping from class IDs to class labels\n",
    "\n",
    "# Initialize the model with the configuration.\n",
    "conf = Config()\n",
    "train_class_counts = [3458, 4440]  # Example class counts for training.\n",
    "id_to_labels = conf.id_to_labels  # Use the configuration's label mapping.\n",
    "\n",
    "# Initialize model\n",
    "model = Plain(conf, train_class_counts, id_to_labels)\n",
    "# Print the model architecture.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with the configurations and load the weights from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.9.0 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint weights/Crop/Plain/Crop_res50_plain_082723-0-epoch=14-valid_mac_acc=91.38.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain(\n",
      "  (net): PlainResNetClassifier(\n",
      "    (feature): ResNetBackbone(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "    (classifier): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint into the model.\n",
    "def load_model_from_checkpoint(checkpoint_path, conf):\n",
    "    \"\"\"\n",
    "    Load the model from the checkpoint file.\n",
    "    Args:\n",
    "        - checkpoint_path: Path to the checkpoint file.\n",
    "        - conf: Configuration object.\n",
    "    \"\"\"\n",
    "    # Use the class method to load from checkpoint.\n",
    "    model = Plain.load_from_checkpoint(checkpoint_path, conf=conf,\n",
    "                                       train_class_counts=[3458, 4440], \n",
    "                                       id_to_labels=conf.id_to_labels)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Initialize the model with configuration and load the checkpoint.\n",
    "conf = Config()\n",
    "\n",
    "# Initialize and load model\n",
    "model = load_model_from_checkpoint(checkpoint_path, conf)\n",
    "# Print the loaded model.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(image_path):\n",
    "    # Define the transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match the input size of the model\n",
    "        transforms.ToTensor(),           # Convert to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "    ])\n",
    "    \n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB mode\n",
    "    image = transform(image)  # Apply the transformations\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to predict the class of the image\n",
    "def predict(model, image_tensor, device):\n",
    "    image_tensor = image_tensor.to(device)  # Move the image tensor to the same device as the model\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        logits = model.net.classifier(model.net.feature(image_tensor))  # Forward pass\n",
    "        preds = torch.argmax(logits, dim=1)  # Get the predicted class\n",
    "    return preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0, Label: Not Tiger\n"
     ]
    }
   ],
   "source": [
    "image_path = 'data/imgs/Leopard (1).jpg'\n",
    "\n",
    "# Determine the device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Preprocess the image\n",
    "image_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Make prediction\n",
    "predicted_class = predict(model, image_tensor, device)\n",
    "\n",
    "# Map the predicted class to the label\n",
    "predicted_label = conf.id_to_labels[predicted_class]\n",
    "print(f\"Predicted Class: {predicted_class}, Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1, Label: Tiger\n"
     ]
    }
   ],
   "source": [
    "image_path = 'data/imgs/Tiger (531).jpg'\n",
    "\n",
    "# Determine the device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Preprocess the image\n",
    "image_tensor = preprocess_image(image_path)\n",
    "\n",
    "# Make prediction\n",
    "predicted_class = predict(model, image_tensor, device)\n",
    "\n",
    "# Map the predicted class to the label\n",
    "predicted_label = conf.id_to_labels[predicted_class]\n",
    "print(f\"Predicted Class: {predicted_class}, Label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
